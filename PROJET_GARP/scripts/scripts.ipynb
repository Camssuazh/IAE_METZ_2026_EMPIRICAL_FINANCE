{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "178be10d",
   "metadata": {},
   "source": [
    "# Analyse de la performance d’une stratégie GARP (Growth at a Reasonable Price)\n",
    "\n",
    "**Master 2 Finance Internationale**\n",
    "\n",
    "Objectif :\n",
    "Analyser la performance d’une stratégie de conviction GARP, en décomposant l’alpha,\n",
    "et en évaluant la persistance du couple rendement–risque face à des benchmarks mondiaux.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15663771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-3.0.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-1.1.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: requests>=2.31 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (2.32.5)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.12.tar.gz (19 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: platformdirs>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (4.5.0)\n",
      "Collecting pytz>=2022.5 (from yfinance)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Downloading frozendict-2.4.7-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.19.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (4.14.2)\n",
      "Collecting curl_cffi<0.14,>=0.7 (from yfinance)\n",
      "  Downloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting protobuf>=3.19.0 (from yfinance)\n",
      "  Downloading protobuf-6.33.5-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting websockets>=13.0 (from yfinance)\n",
      "  Downloading websockets-16.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from curl_cffi<0.14,>=0.7->yfinance) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /home/codespace/.local/lib/python3.12/site-packages (from curl_cffi<0.14,>=0.7->yfinance) (2025.11.12)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-12.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting scipy!=1.9.2,>=1.8 (from statsmodels)\n",
      "  Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=1.12.0->curl_cffi<0.14,>=0.7->yfinance) (2.23)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.5.0)\n",
      "Downloading pandas-3.0.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yfinance-1.1.0-py2.py3-none-any.whl (129 kB)\n",
      "Downloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading statsmodels-0.14.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (10.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozendict-2.4.7-py3-none-any.whl (16 kB)\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "Downloading peewee-3.19.0-py3-none-any.whl (411 kB)\n",
      "Downloading pillow-12.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.33.5-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading websockets-16.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (184 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: multitasking\n",
      "  Building wheel for multitasking (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for multitasking: filename=multitasking-0.0.12-py3-none-any.whl size=15635 sha256=c7a82f0ae6de87ab6f9b716f5b963d1888fe59dbf42ade4b04dafeb0bc3ece59\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/cc/bd/6f/664d62c99327abeef7d86489e6631cbf45b56fbf7ef1d6ef00\n",
      "Successfully built multitasking\n",
      "Installing collected packages: pytz, peewee, multitasking, websockets, threadpoolctl, pyparsing, protobuf, pillow, numpy, kiwisolver, joblib, frozendict, fonttools, et-xmlfile, cycler, scipy, patsy, pandas, openpyxl, curl_cffi, contourpy, yfinance, statsmodels, scikit-learn, matplotlib, seaborn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/26\u001b[0m [seaborn]5/26\u001b[0m [seaborn]ib]n]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 curl_cffi-0.13.0 cycler-0.12.1 et-xmlfile-2.0.0 fonttools-4.61.1 frozendict-2.4.7 joblib-1.5.3 kiwisolver-1.4.9 matplotlib-3.10.8 multitasking-0.0.12 numpy-2.4.2 openpyxl-3.1.5 pandas-3.0.0 patsy-1.0.2 peewee-3.19.0 pillow-12.1.1 protobuf-6.33.5 pyparsing-3.3.2 pytz-2025.2 scikit-learn-1.8.0 scipy-1.17.0 seaborn-0.13.2 statsmodels-0.14.6 threadpoolctl-3.6.0 websockets-16.0 yfinance-1.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# INSTALLATION DES PACKAGES\n",
    "# =========================\n",
    "\n",
    "! pip install pandas numpy yfinance matplotlib seaborn statsmodels openpyxl scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2789ae",
   "metadata": {},
   "source": [
    "## 1. Préparation des données - Portefeuille GARP\n",
    "\n",
    "Cette section vise à importer, nettoyer et harmoniser les données nécessaires à l’analyse empirique :\n",
    "- Actions du portefeuille GARP (Yahoo Finance)\n",
    "- Devise homogène : EUR\n",
    "- Fréquence : mensuelle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5896b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 1. PREPARATION DES DONNEES – PORTEFEUILLE GARP\n",
    "# ======================================================\n",
    "\n",
    "# ----------------------\n",
    "# 1.1 Librairies\n",
    "# ----------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# 1.2 Univers d’investissement\n",
    "# ----------------------\n",
    "# Portefeuille GARP composé de 10 actions internationales\n",
    "# La devise associée à chaque titre est précisée afin de\n",
    "# permettre une conversion rigoureuse en euros\n",
    "\n",
    "garp_stocks = {\n",
    "    \"ADYEN.AS\": \"EUR\",\n",
    "    \"KRI.AT\": \"EUR\",\n",
    "    \"AMZN\": \"USD\",\n",
    "    \"META\": \"USD\",\n",
    "    \"GOOGL\": \"USD\",\n",
    "    \"CSU.TO\": \"CAD\",\n",
    "    \"MELI\": \"USD\",\n",
    "    \"DNP.WA\": \"PLN\",\n",
    "    \"LLY\": \"USD\",\n",
    "    \"KNSL\": \"USD\"\n",
    "}\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# 1.3 Période d’étude\n",
    "# ----------------------\n",
    "start_date = \"2021-02-01\"\n",
    "end_date = \"2026-01-31\"\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# 1.4 Téléchargement des prix ajustés\n",
    "# ----------------------\n",
    "# Les prix ajustés (auto_adjust=True) incluent les dividendes\n",
    "# et sont extraits depuis Yahoo Finance\n",
    "\n",
    "prices = yf.download(\n",
    "    tickers=list(garp_stocks.keys()),\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    auto_adjust=True,\n",
    "    progress=False\n",
    ")[\"Close\"]\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# 1.5 Passage en fréquence mensuelle\n",
    "# ----------------------\n",
    "# Les prix sont retenus en fin de mois afin d’être cohérents\n",
    "# avec les benchmarks utilisés dans l’analyse ultérieure\n",
    "\n",
    "prices_m = prices.resample(\"ME\").last()\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# 1.6 Conversion des prix en euros\n",
    "# ----------------------\n",
    "\n",
    "# Tickers de change Yahoo Finance (devise locale -> EUR)\n",
    "fx_tickers = {\n",
    "    \"USD\": \"USDEUR=X\",\n",
    "    \"CAD\": \"CADEUR=X\",\n",
    "    \"PLN\": \"PLNEUR=X\"\n",
    "}\n",
    "\n",
    "# Téléchargement des taux de change\n",
    "fx = yf.download(\n",
    "    tickers=list(fx_tickers.values()),\n",
    "    start=start_date,\n",
    "    auto_adjust=True,\n",
    "    progress=False\n",
    ")[\"Close\"]\n",
    "\n",
    "# Passage en fréquence mensuelle\n",
    "fx = fx.resample(\"ME\").last()\n",
    "fx.columns = fx_tickers.keys()\n",
    "\n",
    "# Conversion des prix non libellés en EUR\n",
    "prices_eur = prices_m.copy()\n",
    "\n",
    "for ticker, currency in garp_stocks.items():\n",
    "    if currency != \"EUR\":\n",
    "        prices_eur[ticker] = prices_m[ticker] * fx[currency]\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# 1.7 Calcul des rendements simples (simple returns)\n",
    "# ----------------------\n",
    "# Les rendements simples sont utilisés afin d’être cohérents\n",
    "# avec les facteurs Fama-French (exprimés en rendements simples)\n",
    "\n",
    "returns_stocks = prices_eur.pct_change().dropna()\n",
    "\n",
    "# ----------------------\n",
    "# 1.7 bis Traitement des valeurs manquantes\n",
    "# ----------------------\n",
    "# Les valeurs manquantes éventuelles sont remplacées par la\n",
    "# médiane de chaque série afin de limiter l’impact des outliers\n",
    "# et de préserver la structure de distribution des rendements\n",
    "\n",
    "returns_stocks = returns_stocks.apply(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# 1.8 Construction du portefeuille GARP équipondéré\n",
    "# ----------------------\n",
    "# Chaque actif reçoit un poids constant identique\n",
    "\n",
    "n_assets = returns_stocks.shape[1]\n",
    "weights = np.repeat(1 / n_assets, n_assets)\n",
    "\n",
    "# Rendement mensuel du portefeuille GARP\n",
    "garp_portfolio_returns = returns_stocks.dot(weights)\n",
    "garp_portfolio_returns.name = \"GARP_Portfolio\"\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# 1.9 Sauvegarde des données\n",
    "# ----------------------\n",
    "DATA_PROCESSED = Path(\"../data/processed\")\n",
    "DATA_PROCESSED.mkdir(exist_ok=True)\n",
    "\n",
    "returns_stocks.to_csv(DATA_PROCESSED / \"garp_stocks_returns.csv\")\n",
    "garp_portfolio_returns.to_csv(DATA_PROCESSED / \"garp_portfolio_returns.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192cf61f",
   "metadata": {},
   "source": [
    "# 2. Analyse descriptive & performance globale — Portefeuille GARP vs MSCI World\n",
    "\n",
    "Cette section présente une analyse complète de la performance et du profil de risque du portefeuille GARP en comparaison avec le benchmark MSCI World. Nous procédons aux étapes suivantes :\n",
    "\n",
    "- Importation et préparation des données de performance mensuelle.\n",
    "- Calcul des rendements logarithmiques et alignement temporel des séries.\n",
    "- Calcul et visualisation des performances cumulées et des drawdowns.\n",
    "- Estimation des statistiques descriptives classiques et avancées (rendement annualisé, volatilité, Sharpe, skewness, kurtosis, Sortino, VaR, CVaR).\n",
    "- Calcul de l’Information Ratio et du Tracking Error pour mesurer la valeur ajoutée du portefeuille par rapport au benchmark.\n",
    "- Estimation du modèle CAPM pour extraire alpha, beta et leur significativité.\n",
    "- Test statistique de la robustesse du Sharpe ratio.\n",
    "- Calcul du downside beta pour évaluer le comportement en marché baissier.\n",
    "- Analyse de corrélation entre GARP et MSCI World.\n",
    "- Export des résultats sous forme de tableaux CSV et graphiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cef1d4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7982/1239410165.py:42: Pandas4Warning: Sorting by default when concatenating all DatetimeIndex is deprecated.  In the future, pandas will respect the default of `sort=False`. Specify `sort=True` or `sort=False` to silence this message. If you see this warnings when not directly calling concat, report a bug to pandas.\n",
      "  returns_comp = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TABLEAU DE PERFORMANCE ===\n",
      "            Rendement annualisé  Volatilité annualisée  Sharpe  Skewness  \\\n",
      "GARP                     0.1664                 0.2139  0.6325    0.0772   \n",
      "MSCI_World               0.0784                 0.1228  0.3855   -0.6024   \n",
      "\n",
      "            Kurtosis  Max Drawdown  Sortino  VaR 95%  CVaR 95%  \\\n",
      "GARP         -0.2482       -0.2978   1.0687  -0.0863   -0.0968   \n",
      "MSCI_World   -0.0436       -0.2000   0.5544  -0.0630   -0.0726   \n",
      "\n",
      "            Tracking Error  Information Ratio  Alpha CAPM  Beta CAPM  \\\n",
      "GARP                0.1384             0.6354      0.0704     1.3718   \n",
      "MSCI_World             NaN                NaN         NaN        NaN   \n",
      "\n",
      "            p-value Alpha  R² CAPM  t-stat Sharpe  Downside Beta  \n",
      "GARP               0.3231   0.6226         4.1478         1.1786  \n",
      "MSCI_World            NaN      NaN            NaN            NaN  \n",
      "\n",
      "=== MATRICE DE CORRÉLATION ===\n",
      "              GARP  MSCI_World      RF\n",
      "GARP        1.0000      0.7932  0.1904\n",
      "MSCI_World  0.7932      1.0000  0.0903\n",
      "RF          0.1904      0.0903  1.0000\n",
      "\n",
      "Section 2 terminée avec succès.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 2. ANALYSE DESCRIPTIVE & PERFORMANCE GLOBALE\n",
    "# Portefeuille GARP vs MSCI World\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2.1 Chemins\n",
    "# -----------------------------\n",
    "DATA_RAW = Path(\"../data/raw\")\n",
    "RESULTS_FIGURES = Path(\"../results/figures\")\n",
    "RESULTS_TABLES = Path(\"../results/tables\")\n",
    "RESULTS_FIGURES.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_TABLES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2.2 Import MSCI World\n",
    "# -----------------------------\n",
    "msci_world = pd.read_excel(DATA_RAW / \"msci_world_factset.xlsx\")\n",
    "\n",
    "msci_world.iloc[:, 0] = pd.to_datetime(msci_world.iloc[:, 0])\n",
    "msci_world.set_index(msci_world.columns[0], inplace=True)\n",
    "msci_world = msci_world.sort_index().iloc[:, 0]\n",
    "msci_world.name = \"MSCI_World\"\n",
    "\n",
    "# Simple returns MSCI (cohérent Fama-French)\n",
    "r_msci = msci_world.pct_change()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2.3 Alignement des séries\n",
    "# -----------------------------\n",
    "returns_comp = pd.concat(\n",
    "    [garp_portfolio_returns, r_msci], axis=1\n",
    ").dropna()\n",
    "\n",
    "returns_comp.columns = [\"GARP\", \"MSCI_World\"]\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 2.4 Intégration du RF Fama-French (mensuel, en %)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "ff = pd.read_excel(DATA_RAW / \"fama_french_3factors.xlsx\")\n",
    "\n",
    "ff.iloc[:, 0] = pd.to_datetime(ff.iloc[:, 0])\n",
    "ff.set_index(ff.columns[0], inplace=True)\n",
    "ff = ff.sort_index()\n",
    "\n",
    "ff.columns = [\"Mkt_RF\", \"SMB\", \"HML\", \"RF\"]\n",
    "\n",
    "# Conversion % -> décimal\n",
    "ff = ff / 100\n",
    "\n",
    "# Alignement temporel avec les rendements\n",
    "returns_comp = returns_comp.join(ff[\"RF\"], how=\"inner\")\n",
    "\n",
    "# Excess returns cohérents\n",
    "excess_returns = returns_comp[[\"GARP\",\"MSCI_World\"]].sub(\n",
    "    returns_comp[\"RF\"], axis=0\n",
    ")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 2.5 PERFORMANCE CUMULÉE\n",
    "# ======================================================\n",
    "\n",
    "cumulative_perf = (1 + returns_comp[[\"GARP\",\"MSCI_World\"]]).cumprod()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cumulative_perf[\"GARP\"], label=\"GARP\", linewidth=2)\n",
    "plt.plot(cumulative_perf[\"MSCI_World\"], label=\"MSCI World\", linestyle=\"--\")\n",
    "plt.title(\"Performance cumulée (simple returns)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FIGURES / \"2_cumulative_performance.png\")\n",
    "plt.close()\n",
    "\n",
    "# ======================================================\n",
    "# 2.6 DRAWDOWNS\n",
    "# ======================================================\n",
    "\n",
    "rolling_max = cumulative_perf.cummax()\n",
    "drawdowns = cumulative_perf / rolling_max - 1\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(drawdowns[\"GARP\"], label=\"GARP\", linewidth=2)\n",
    "plt.plot(drawdowns[\"MSCI_World\"], label=\"MSCI World\", linestyle=\"--\")\n",
    "plt.title(\"Drawdowns\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FIGURES / \"2_drawdowns.png\")\n",
    "plt.close()\n",
    "\n",
    "# ======================================================\n",
    "# 2.7 STATISTIQUES DESCRIPTIVES\n",
    "# ======================================================\n",
    "\n",
    "stats_table = pd.DataFrame(index=[\"GARP\", \"MSCI_World\"])\n",
    "\n",
    "stats_table[\"Rendement annualisé\"] = returns_comp.mean() * 12\n",
    "stats_table[\"Volatilité annualisée\"] = returns_comp.std() * np.sqrt(12)\n",
    "stats_table[\"Sharpe\"] = (\n",
    "    excess_returns.mean() * 12\n",
    ") / (returns_comp.std() * np.sqrt(12))\n",
    "\n",
    "stats_table[\"Skewness\"] = returns_comp.skew()\n",
    "stats_table[\"Kurtosis\"] = returns_comp.kurtosis()\n",
    "stats_table[\"Max Drawdown\"] = drawdowns.min()\n",
    "\n",
    "# Sortino\n",
    "downside_std = excess_returns.apply(\n",
    "    lambda x: np.sqrt(np.mean(np.minimum(x, 0)**2)) * np.sqrt(12)\n",
    ")\n",
    "\n",
    "stats_table[\"Sortino\"] = (\n",
    "    excess_returns.mean() * 12\n",
    ") / downside_std\n",
    "\n",
    "# VaR & CVaR 95%\n",
    "stats_table[\"VaR 95%\"] = returns_comp.quantile(0.05)\n",
    "stats_table[\"CVaR 95%\"] = returns_comp.apply(\n",
    "    lambda x: x[x <= x.quantile(0.05)].mean()\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# 2.8 INFORMATION RATIO & TRACKING ERROR\n",
    "# ======================================================\n",
    "\n",
    "active_returns = returns_comp[\"GARP\"] - returns_comp[\"MSCI_World\"]\n",
    "\n",
    "tracking_error = active_returns.std() * np.sqrt(12)\n",
    "information_ratio = (active_returns.mean() * 12) / tracking_error\n",
    "\n",
    "stats_table.loc[\"GARP\", \"Tracking Error\"] = tracking_error\n",
    "stats_table.loc[\"GARP\", \"Information Ratio\"] = information_ratio\n",
    "\n",
    "# ======================================================\n",
    "# 2.9 ALPHA CAPM\n",
    "# ======================================================\n",
    "\n",
    "Y = excess_returns[\"GARP\"]\n",
    "X = sm.add_constant(excess_returns[\"MSCI_World\"])\n",
    "\n",
    "model = sm.OLS(Y, X).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":3})\n",
    "\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "alpha = model.params[\"const\"] * 12\n",
    "beta = model.params[\"MSCI_World\"]\n",
    "alpha_pval = model.pvalues[\"const\"]\n",
    "\n",
    "stats_table.loc[\"GARP\", \"Alpha CAPM\"] = alpha\n",
    "stats_table.loc[\"GARP\", \"Beta CAPM\"] = beta\n",
    "stats_table.loc[\"GARP\", \"p-value Alpha\"] = alpha_pval\n",
    "stats_table.loc[\"GARP\", \"R² CAPM\"] = model.rsquared\n",
    "\n",
    "# ======================================================\n",
    "# 2.10 TEST STATISTIQUE DU SHARPE\n",
    "# Approximation asymptotique\n",
    "# ======================================================\n",
    "\n",
    "T = len(returns_comp)\n",
    "\n",
    "def sharpe_test(sr, T):\n",
    "    return sr * np.sqrt(T)\n",
    "\n",
    "sharpe_tstat = sharpe_test(stats_table.loc[\"GARP\",\"Sharpe\"], T)\n",
    "stats_table.loc[\"GARP\",\"t-stat Sharpe\"] = sharpe_tstat\n",
    "\n",
    "# ======================================================\n",
    "# 2.11 DOWNSIDE BETA\n",
    "# ======================================================\n",
    "\n",
    "market_down = returns_comp[\"MSCI_World\"] < 0\n",
    "downside_beta = np.cov(\n",
    "    returns_comp[\"GARP\"][market_down],\n",
    "    returns_comp[\"MSCI_World\"][market_down]\n",
    ")[0,1] / np.var(returns_comp[\"MSCI_World\"][market_down])\n",
    "\n",
    "stats_table.loc[\"GARP\",\"Downside Beta\"] = downside_beta\n",
    "\n",
    "# ======================================================\n",
    "# 2.12 CORRÉLATION\n",
    "# ======================================================\n",
    "\n",
    "corr_matrix = returns_comp.corr()\n",
    "\n",
    "# ======================================================\n",
    "# 2.13 EXPORT DES TABLEAUX\n",
    "# ======================================================\n",
    "\n",
    "stats_table.to_csv(RESULTS_TABLES / \"2_performance_statistics.csv\")\n",
    "corr_matrix.to_csv(RESULTS_TABLES / \"2_correlation_matrix.csv\")\n",
    "\n",
    "print(\"\\n=== TABLEAU DE PERFORMANCE ===\")\n",
    "print(stats_table.round(4))\n",
    "\n",
    "print(\"\\n=== MATRICE DE CORRÉLATION ===\")\n",
    "print(corr_matrix.round(4))\n",
    "\n",
    "print(\"\\nSection 2 terminée avec succès.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4645c7ef",
   "metadata": {},
   "source": [
    "# 3. Caractérisation stylistique — Portefeuille GARP vs MSCI World Growth & Value\n",
    "\n",
    "Cette section analyse la caractérisation stylistique du portefeuille GARP en le comparant aux indices MSCI World Growth et MSCI World Value. L’objectif est de comprendre dans quelle mesure le portefeuille s’expose aux styles de marché « Growth » (croissance) et « Value » (valeur), par le biais des étapes suivantes :\n",
    "\n",
    "- Import et préparation des séries historiques des indices Growth et Value.\n",
    "- Calcul des rendements logarithmiques mensuels et alignement temporel avec GARP.\n",
    "- Calcul et visualisation des performances cumulées des trois séries.\n",
    "- Estimation des statistiques descriptives clés : rendement, volatilité, ratio de Sharpe, drawdowns, corrélations.\n",
    "- Calcul des metrics de suivi de la performance active : Tracking Error et Information Ratio contre Growth et Value.\n",
    "- Régression stylistique multivariée : modélisation du rendement excédentaire de GARP en fonction des facteurs Growth et Value pour obtenir alpha, beta et qualité du modèle.\n",
    "- Normalisation des poids stylistiques (beta) pour interprétation.\n",
    "- Analyse dynamique par rolling regression sur 36 mois des expositions Growth et Value.\n",
    "- Calcul des downside betas, pour évaluer la sensibilité aux marchés baissiers Growth et Value.\n",
    "- Export des résultats sous forme de tableaux CSV et graphiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dc5c6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7982/1070573345.py:43: Pandas4Warning: Sorting by default when concatenating all DatetimeIndex is deprecated.  In the future, pandas will respect the default of `sort=False`. Specify `sort=True` or `sort=False` to silence this message. If you see this warnings when not directly calling concat, report a bug to pandas.\n",
      "  returns_style = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TABLEAU STYLISTIQUE ===\n",
      "        Rendement annualisé  Volatilité annualisée  Sharpe  Max Drawdown  \\\n",
      "GARP                 0.1664                 0.2139  0.6325       -0.2978   \n",
      "Growth               0.1018                 0.1551  0.4556       -0.2693   \n",
      "Value                0.0533                 0.1205  0.1845       -0.1438   \n",
      "\n",
      "        Tracking Error vs Growth  IR vs Growth  Tracking Error vs Value  \\\n",
      "GARP                      0.1165        0.5548                   0.1822   \n",
      "Growth                       NaN           NaN                      NaN   \n",
      "Value                        NaN           NaN                      NaN   \n",
      "\n",
      "        IR vs Value  Alpha (Growth+Value)  Beta Growth  Beta Value  \\\n",
      "GARP         0.6205                0.0536       1.1251      0.0959   \n",
      "Growth          NaN                   NaN          NaN         NaN   \n",
      "Value           NaN                   NaN          NaN         NaN   \n",
      "\n",
      "        p-value Alpha  R² Style Model  Weight Growth (norm.)  \\\n",
      "GARP           0.3745          0.7172                 0.9215   \n",
      "Growth            NaN             NaN                    NaN   \n",
      "Value             NaN             NaN                    NaN   \n",
      "\n",
      "        Weight Value (norm.)  Downside Beta vs Growth  Downside Beta vs Value  \n",
      "GARP                  0.0785                   1.0924                  0.6569  \n",
      "Growth                   NaN                      NaN                     NaN  \n",
      "Value                    NaN                      NaN                     NaN  \n",
      "\n",
      "=== MATRICE DE CORRÉLATION ===\n",
      "          GARP  Growth   Value      RF\n",
      "GARP    1.0000  0.8476  0.5250  0.1904\n",
      "Growth  0.8476  1.0000  0.5738  0.1884\n",
      "Value   0.5250  0.5738  1.0000 -0.0575\n",
      "RF      0.1904  0.1884 -0.0575  1.0000\n",
      "\n",
      "=== Résumé régression stylistique ===\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   GARP   R-squared:                       0.717\n",
      "Model:                            OLS   Adj. R-squared:                  0.703\n",
      "Method:                 Least Squares   F-statistic:                     28.94\n",
      "Date:                Thu, 12 Feb 2026   Prob (F-statistic):           1.69e-08\n",
      "Time:                        11:36:56   Log-Likelihood:                 86.613\n",
      "No. Observations:                  43   AIC:                            -167.2\n",
      "Df Residuals:                      40   BIC:                            -161.9\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:                  HAC                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0045      0.005      0.888      0.375      -0.005       0.014\n",
      "Growth         1.1251      0.162      6.931      0.000       0.807       1.443\n",
      "Value          0.0959      0.170      0.564      0.573      -0.238       0.429\n",
      "==============================================================================\n",
      "Omnibus:                        2.411   Durbin-Watson:                   1.499\n",
      "Prob(Omnibus):                  0.300   Jarque-Bera (JB):                1.435\n",
      "Skew:                          -0.389   Prob(JB):                        0.488\n",
      "Kurtosis:                       3.441   Cond. No.                         40.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 3 lags and without small sample correction\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 3. CARACTÉRISATION STYLISTIQUE\n",
    "# GARP vs MSCI World Growth & Value\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3.1 Import des indices Growth & Value\n",
    "# ------------------------------------------------------\n",
    "\n",
    "DATA_RAW = Path(\"../data/raw\")\n",
    "RESULTS_FIGURES = Path(\"../results/figures\")\n",
    "RESULTS_TABLES = Path(\"../results/tables\")\n",
    "\n",
    "msci_growth = pd.read_excel(DATA_RAW / \"msci_world_growth_factset.xlsx\")\n",
    "msci_value = pd.read_excel(DATA_RAW / \"msci_world_value_factset.xlsx\")\n",
    "\n",
    "def prepare_index(df, name):\n",
    "    df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n",
    "    df.set_index(df.columns[0], inplace=True)\n",
    "    df = df.sort_index().iloc[:, 0]\n",
    "    df.name = name\n",
    "    return df\n",
    "\n",
    "msci_growth = prepare_index(msci_growth, \"MSCI_World_Growth\")\n",
    "msci_value = prepare_index(msci_value, \"MSCI_World_Value\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3.2 Simple returns (cohérent Fama-French)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "r_growth = msci_growth.pct_change()\n",
    "r_value = msci_value.pct_change()\n",
    "\n",
    "returns_style = pd.concat(\n",
    "    [garp_portfolio_returns, r_growth, r_value], axis=1\n",
    ").dropna()\n",
    "\n",
    "returns_style.columns = [\"GARP\", \"Growth\", \"Value\"]\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3.3 Intégration du RF Fama-French\n",
    "# ------------------------------------------------------\n",
    "\n",
    "ff = pd.read_excel(DATA_RAW / \"fama_french_3factors.xlsx\")\n",
    "\n",
    "ff.iloc[:, 0] = pd.to_datetime(ff.iloc[:, 0])\n",
    "ff.set_index(ff.columns[0], inplace=True)\n",
    "ff = ff.sort_index()\n",
    "\n",
    "ff.columns = [\"Mkt_RF\", \"SMB\", \"HML\", \"RF\"]\n",
    "\n",
    "# Conversion % -> décimal\n",
    "ff = ff / 100\n",
    "\n",
    "# Alignement temporel\n",
    "returns_style = returns_style.join(ff[\"RF\"], how=\"inner\")\n",
    "\n",
    "# Excess returns cohérents\n",
    "excess_returns_style = returns_style[[\"GARP\",\"Growth\",\"Value\"]].sub(\n",
    "    returns_style[\"RF\"], axis=0\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# 3.4 PERFORMANCE CUMULÉE\n",
    "# ======================================================\n",
    "\n",
    "cumulative_style = (1 + returns_style[[\"GARP\",\"Growth\",\"Value\"]]).cumprod()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cumulative_style[\"GARP\"], label=\"GARP\", linewidth=2)\n",
    "plt.plot(cumulative_style[\"Growth\"], label=\"Growth\", linestyle=\"--\")\n",
    "plt.plot(cumulative_style[\"Value\"], label=\"Value\", linestyle=\":\")\n",
    "plt.title(\"Performance cumulée – GARP vs Growth & Value\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FIGURES / \"3_cumulative_style.png\")\n",
    "plt.close()\n",
    "\n",
    "# ======================================================\n",
    "# 3.5 STATISTIQUES DESCRIPTIVES\n",
    "# ======================================================\n",
    "\n",
    "style_stats = pd.DataFrame(index=[\"GARP\",\"Growth\",\"Value\"])\n",
    "\n",
    "style_stats[\"Rendement annualisé\"] = returns_style[[\"GARP\",\"Growth\",\"Value\"]].mean() * 12\n",
    "style_stats[\"Volatilité annualisée\"] = returns_style[[\"GARP\",\"Growth\",\"Value\"]].std() * np.sqrt(12)\n",
    "style_stats[\"Sharpe\"] = (\n",
    "    excess_returns_style.mean() * 12\n",
    ") / (returns_style.std() * np.sqrt(12))\n",
    "\n",
    "# Drawdowns\n",
    "rolling_max = cumulative_style.cummax()\n",
    "drawdowns = cumulative_style / rolling_max - 1\n",
    "style_stats[\"Max Drawdown\"] = drawdowns.min()\n",
    "\n",
    "# Corrélation\n",
    "corr_matrix_style = returns_style.corr()\n",
    "\n",
    "# ======================================================\n",
    "# 3.6 INFORMATION RATIO\n",
    "# ======================================================\n",
    "\n",
    "for benchmark in [\"Growth\", \"Value\"]:\n",
    "    active = returns_style[\"GARP\"] - returns_style[benchmark]\n",
    "    te = active.std() * np.sqrt(12)\n",
    "    ir = (active.mean() * 12) / te\n",
    "    \n",
    "    style_stats.loc[\"GARP\", f\"Tracking Error vs {benchmark}\"] = te\n",
    "    style_stats.loc[\"GARP\", f\"IR vs {benchmark}\"] = ir\n",
    "\n",
    "# ======================================================\n",
    "# 3.7 RÉGRESSION STYLISTIQUE\n",
    "# GARP = alpha + b1*Growth + b2*Value\n",
    "# ======================================================\n",
    "\n",
    "Y = excess_returns_style[\"GARP\"]\n",
    "X = excess_returns_style[[\"Growth\",\"Value\"]]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model_style = sm.OLS(Y, X).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":3})\n",
    "\n",
    "alpha_style = model_style.params[\"const\"] * 12\n",
    "beta_growth = model_style.params[\"Growth\"]\n",
    "beta_value = model_style.params[\"Value\"]\n",
    "\n",
    "style_stats.loc[\"GARP\",\"Alpha (Growth+Value)\"] = alpha_style\n",
    "style_stats.loc[\"GARP\",\"Beta Growth\"] = beta_growth\n",
    "style_stats.loc[\"GARP\",\"Beta Value\"] = beta_value\n",
    "style_stats.loc[\"GARP\",\"p-value Alpha\"] = model_style.pvalues[\"const\"]\n",
    "style_stats.loc[\"GARP\",\"R² Style Model\"] = model_style.rsquared\n",
    "\n",
    "# ======================================================\n",
    "# 3.8 POIDS STYLISTIQUES NORMALISÉS\n",
    "# ======================================================\n",
    "\n",
    "beta_sum = beta_growth + beta_value\n",
    "style_stats.loc[\"GARP\",\"Weight Growth (norm.)\"] = beta_growth / beta_sum\n",
    "style_stats.loc[\"GARP\",\"Weight Value (norm.)\"] = beta_value / beta_sum\n",
    "\n",
    "# ======================================================\n",
    "# 3.9 ROLLING STYLE EXPOSURE (36 mois)\n",
    "# ======================================================\n",
    "\n",
    "window = 36\n",
    "rolling_betas_growth = []\n",
    "rolling_betas_value = []\n",
    "dates = []\n",
    "\n",
    "for i in range(window, len(excess_returns_style)):\n",
    "    Y_roll = excess_returns_style[\"GARP\"].iloc[i-window:i]\n",
    "    X_roll = excess_returns_style[[\"Growth\",\"Value\"]].iloc[i-window:i]\n",
    "    X_roll = sm.add_constant(X_roll)\n",
    "    \n",
    "    model_roll = sm.OLS(Y_roll, X_roll).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":3})\n",
    "    \n",
    "    rolling_betas_growth.append(model_roll.params[\"Growth\"])\n",
    "    rolling_betas_value.append(model_roll.params[\"Value\"])\n",
    "    dates.append(excess_returns_style.index[i])\n",
    "\n",
    "rolling_df = pd.DataFrame({\n",
    "    \"Beta Growth\": rolling_betas_growth,\n",
    "    \"Beta Value\": rolling_betas_value\n",
    "}, index=dates)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(rolling_df[\"Beta Growth\"], label=\"Rolling Beta Growth\")\n",
    "plt.plot(rolling_df[\"Beta Value\"], label=\"Rolling Beta Value\")\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.title(\"Rolling Style Exposure (36 mois)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FIGURES / \"3_rolling_style_exposure.png\")\n",
    "plt.close()\n",
    "\n",
    "# ======================================================\n",
    "# 3.10 DOWNSIDE BETAS\n",
    "# ======================================================\n",
    "\n",
    "for benchmark in [\"Growth\",\"Value\"]:\n",
    "    mask = returns_style[benchmark] < 0\n",
    "    downside_beta = np.cov(\n",
    "        returns_style[\"GARP\"][mask],\n",
    "        returns_style[benchmark][mask]\n",
    "    )[0,1] / np.var(returns_style[benchmark][mask])\n",
    "    \n",
    "    style_stats.loc[\"GARP\", f\"Downside Beta vs {benchmark}\"] = downside_beta\n",
    "\n",
    "# ======================================================\n",
    "# 3.11 EXPORT\n",
    "# ======================================================\n",
    "\n",
    "style_stats.to_csv(RESULTS_TABLES / \"3_style_statistics.csv\")\n",
    "corr_matrix_style.to_csv(RESULTS_TABLES / \"3_style_correlation_matrix.csv\")\n",
    "\n",
    "print(\"\\n=== TABLEAU STYLISTIQUE ===\")\n",
    "print(style_stats.round(4))\n",
    "\n",
    "print(\"\\n=== MATRICE DE CORRÉLATION ===\")\n",
    "print(corr_matrix_style.round(4))\n",
    "\n",
    "print(\"\\n=== Résumé régression stylistique ===\")\n",
    "print(model_style.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6e6f5",
   "metadata": {},
   "source": [
    "# 4. Décomposition factorielle — CAPM, Fama-French 3F et Carhart 4F\n",
    "\n",
    "Cette section effectue une décomposition factorielle des rendements du portefeuille GARP en utilisant les modèles financiers classiques :\n",
    "\n",
    "- **CAPM** : Modèle du marché avec une seule factorisation.\n",
    "- **Fama-French 3 facteurs (FF3)** : Ajoute les facteurs de taille (SMB) et valeur (HML) au marché.\n",
    "- **Carhart 4 facteurs (4F)** : Ajoute le facteur momentum (MOM) au modèle FF3.\n",
    "\n",
    "Les objectifs sont :\n",
    "\n",
    "1. Importer les facteurs et préparer les données.\n",
    "2. Estimer les modèles linéaires avec erreurs robustes Newey-West.\n",
    "3. Résumer les résultats en termes d’alpha, R² et betas.\n",
    "4. Décomposer la performance économique annuelle selon le modèle Carhart.\n",
    "5. Calculer un alpha glissant sur 36 mois pour suivre l’évolution de la surperformance.\n",
    "6. Tester l’autocorrélation des résidus via le test de Ljung-Box.\n",
    "7. Exporter les résultats sous forme de tableaux et graphiques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de6872ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7982/1161134184.py:50: Pandas4Warning: Sorting by default when concatenating all DatetimeIndex is deprecated.  In the future, pandas will respect the default of `sort=False`. Specify `sort=True` or `sort=False` to silence this message. If you see this warnings when not directly calling concat, report a bug to pandas.\n",
      "  data = pd.concat([garp_portfolio_returns, factors], axis=1).dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= CAPM =========\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            GARP_Excess   R-squared:                       0.684\n",
      "Model:                            OLS   Adj. R-squared:                  0.678\n",
      "Method:                 Least Squares   F-statistic:                     181.6\n",
      "Date:                Thu, 12 Feb 2026   Prob (F-statistic):           3.22e-19\n",
      "Time:                        11:37:14   Log-Likelihood:                 113.90\n",
      "No. Observations:                  58   AIC:                            -223.8\n",
      "Df Residuals:                      56   BIC:                            -219.7\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:                  HAC                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0054      0.005      1.175      0.240      -0.004       0.014\n",
      "Mkt_RF         1.1209      0.083     13.476      0.000       0.958       1.284\n",
      "==============================================================================\n",
      "Omnibus:                        0.407   Durbin-Watson:                   1.807\n",
      "Prob(Omnibus):                  0.816   Jarque-Bera (JB):                0.572\n",
      "Skew:                          -0.114   Prob(JB):                        0.751\n",
      "Kurtosis:                       2.570   Cond. No.                         22.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 3 lags and without small sample correction\n",
      "\n",
      "========= FAMA-FRENCH 3F =========\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            GARP_Excess   R-squared:                       0.776\n",
      "Model:                            OLS   Adj. R-squared:                  0.764\n",
      "Method:                 Least Squares   F-statistic:                     92.19\n",
      "Date:                Thu, 12 Feb 2026   Prob (F-statistic):           3.10e-21\n",
      "Time:                        11:37:14   Log-Likelihood:                 123.92\n",
      "No. Observations:                  58   AIC:                            -239.8\n",
      "Df Residuals:                      54   BIC:                            -231.6\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:                  HAC                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0070      0.004      1.718      0.086      -0.001       0.015\n",
      "Mkt_RF         1.0732      0.087     12.316      0.000       0.902       1.244\n",
      "SMB           -0.1561      0.114     -1.364      0.173      -0.380       0.068\n",
      "HML           -0.4339      0.068     -6.378      0.000      -0.567      -0.301\n",
      "==============================================================================\n",
      "Omnibus:                        4.054   Durbin-Watson:                   1.790\n",
      "Prob(Omnibus):                  0.132   Jarque-Bera (JB):                3.431\n",
      "Skew:                          -0.327   Prob(JB):                        0.180\n",
      "Kurtosis:                       3.996   Cond. No.                         38.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 3 lags and without small sample correction\n",
      "\n",
      "========= CARHART 4F =========\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            GARP_Excess   R-squared:                       0.777\n",
      "Model:                            OLS   Adj. R-squared:                  0.760\n",
      "Method:                 Least Squares   F-statistic:                     92.45\n",
      "Date:                Thu, 12 Feb 2026   Prob (F-statistic):           3.05e-23\n",
      "Time:                        11:37:14   Log-Likelihood:                 123.98\n",
      "No. Observations:                  58   AIC:                            -238.0\n",
      "Df Residuals:                      53   BIC:                            -227.7\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:                  HAC                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0070      0.004      1.758      0.079      -0.001       0.015\n",
      "Mkt_RF         1.0669      0.101     10.577      0.000       0.869       1.265\n",
      "SMB           -0.1716      0.102     -1.683      0.092      -0.371       0.028\n",
      "HML           -0.4378      0.068     -6.463      0.000      -0.571      -0.305\n",
      "MOM           -0.0409      0.118     -0.347      0.728      -0.272       0.190\n",
      "==============================================================================\n",
      "Omnibus:                        3.586   Durbin-Watson:                   1.802\n",
      "Prob(Omnibus):                  0.166   Jarque-Bera (JB):                2.919\n",
      "Skew:                          -0.285   Prob(JB):                        0.232\n",
      "Kurtosis:                       3.940   Cond. No.                         41.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 3 lags and without small sample correction\n",
      "\n",
      "======= SYNTHESE FACTORIELLE =======\n",
      "\n",
      "            Alpha mensuel  Alpha annualisé  p-value Alpha      R²  \\\n",
      "CAPM               0.0054           0.0646         0.2400  0.6839   \n",
      "FF3                0.0070           0.0836         0.0857  0.7762   \n",
      "Carhart 4F         0.0070           0.0844         0.0788  0.7767   \n",
      "\n",
      "            Beta_Mkt_RF  Beta_SMB  Beta_HML  Beta_MOM  \n",
      "CAPM             1.1209       NaN       NaN       NaN  \n",
      "FF3              1.0732   -0.1561   -0.4339       NaN  \n",
      "Carhart 4F       1.0669   -0.1716   -0.4378   -0.0409  \n",
      "\n",
      "======= CONTRIBUTION ANNUALISEE =======\n",
      "\n",
      "Alpha             0.0844\n",
      "Marché            0.1087\n",
      "Taille (SMB)      0.0136\n",
      "Valeur (HML)     -0.0267\n",
      "Momentum (MOM)   -0.0011\n",
      "dtype: float64\n",
      "\n",
      "======= TEST LJUNG-BOX (résidus Carhart) =======\n",
      "\n",
      "    lb_stat  lb_pvalue\n",
      "6  3.664403   0.721983\n",
      "\n",
      "Section 4 terminée avec succès.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 4. DECOMPOSITION FACTORIELLE\n",
    "# CAPM – Fama-French 3F – Carhart 4F\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "RESULTS_TABLES = Path(\"../results/tables\")\n",
    "RESULTS_FIGURES = Path(\"../results/figures\")\n",
    "DATA_RAW = Path(\"../data/raw\")\n",
    "\n",
    "RESULTS_TABLES.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_FIGURES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4.1 Import facteurs Fama-French + Momentum\n",
    "# ---------------------------------------------------\n",
    "\n",
    "ff = pd.read_excel(DATA_RAW / \"fama_french_3factors.xlsx\")\n",
    "mom = pd.read_excel(DATA_RAW / \"momentum_factor.xlsx\")  # facteur MOM (Carhart)\n",
    "\n",
    "# Préparation des facteurs\n",
    "def prepare_factor(df):\n",
    "    df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])\n",
    "    df.set_index(df.columns[0], inplace=True)\n",
    "    return df.sort_index()\n",
    "\n",
    "ff = prepare_factor(ff)\n",
    "mom = prepare_factor(mom)\n",
    "\n",
    "ff.columns = [\"Mkt_RF\", \"SMB\", \"HML\", \"RF\"]\n",
    "mom.columns = [\"MOM\"]\n",
    "\n",
    "# Conversion % -> décimal\n",
    "ff = ff / 100\n",
    "mom = mom / 100\n",
    "\n",
    "# Fusion des facteurs\n",
    "factors = pd.concat([ff, mom], axis=1)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4.2 Alignement avec portefeuille\n",
    "# ---------------------------------------------------\n",
    "\n",
    "data = pd.concat([garp_portfolio_returns, factors], axis=1).dropna()\n",
    "data[\"GARP_Excess\"] = data[\"GARP_Portfolio\"] - data[\"RF\"]\n",
    "\n",
    "Y = data[\"GARP_Excess\"]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4.3 Définition des modèles\n",
    "# ---------------------------------------------------\n",
    "\n",
    "X_capm = sm.add_constant(data[[\"Mkt_RF\"]])\n",
    "X_ff3 = sm.add_constant(data[[\"Mkt_RF\",\"SMB\",\"HML\"]])\n",
    "X_carhart = sm.add_constant(data[[\"Mkt_RF\",\"SMB\",\"HML\",\"MOM\"]])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4.4 Estimation avec erreurs robustes Newey-West\n",
    "# ---------------------------------------------------\n",
    "\n",
    "model_capm = sm.OLS(Y, X_capm).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":3})\n",
    "model_ff3 = sm.OLS(Y, X_ff3).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":3})\n",
    "model_carhart = sm.OLS(Y, X_carhart).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":3})\n",
    "\n",
    "print(\"\\n========= CAPM =========\\n\")\n",
    "print(model_capm.summary())\n",
    "\n",
    "print(\"\\n========= FAMA-FRENCH 3F =========\\n\")\n",
    "print(model_ff3.summary())\n",
    "\n",
    "print(\"\\n========= CARHART 4F =========\\n\")\n",
    "print(model_carhart.summary())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4.5 Tableau synthèse\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def extract_results(model, name):\n",
    "    return pd.Series({\n",
    "        \"Alpha mensuel\": model.params[\"const\"],\n",
    "        \"Alpha annualisé\": model.params[\"const\"] * 12,\n",
    "        \"p-value Alpha\": model.pvalues[\"const\"],\n",
    "        \"R²\": model.rsquared\n",
    "    }, name=name)\n",
    "\n",
    "results_summary = pd.concat([\n",
    "    extract_results(model_capm, \"CAPM\"),\n",
    "    extract_results(model_ff3, \"FF3\"),\n",
    "    extract_results(model_carhart, \"Carhart 4F\")\n",
    "], axis=1).T\n",
    "\n",
    "# Ajout des betas Carhart\n",
    "for factor in [\"Mkt_RF\",\"SMB\",\"HML\",\"MOM\"]:\n",
    "    results_summary[f\"Beta_{factor}\"] = [\n",
    "        model_capm.params.get(factor, np.nan),\n",
    "        model_ff3.params.get(factor, np.nan),\n",
    "        model_carhart.params.get(factor, np.nan)\n",
    "    ]\n",
    "\n",
    "results_summary.to_csv(RESULTS_TABLES / \"4_factor_models_summary.csv\")\n",
    "\n",
    "print(\"\\n======= SYNTHESE FACTORIELLE =======\\n\")\n",
    "print(results_summary.round(4))\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4.6 Décomposition économique (Carhart)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "mean_factors = data[[\"Mkt_RF\",\"SMB\",\"HML\",\"MOM\"]].mean()\n",
    "params = model_carhart.params\n",
    "\n",
    "contribution = pd.Series({\n",
    "    \"Alpha\": params[\"const\"] * 12,\n",
    "    \"Marché\": params[\"Mkt_RF\"] * mean_factors[\"Mkt_RF\"] * 12,\n",
    "    \"Taille (SMB)\": params[\"SMB\"] * mean_factors[\"SMB\"] * 12,\n",
    "    \"Valeur (HML)\": params[\"HML\"] * mean_factors[\"HML\"] * 12,\n",
    "    \"Momentum (MOM)\": params[\"MOM\"] * mean_factors[\"MOM\"] * 12\n",
    "})\n",
    "\n",
    "contribution.to_csv(RESULTS_TABLES / \"4_factor_contribution_carhart.csv\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "contribution.plot(kind=\"bar\")\n",
    "plt.title(\"Décomposition de la performance – Modèle Carhart 4F\")\n",
    "plt.ylabel(\"Contribution annualisée\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FIGURES / \"4_factor_contribution_carhart.png\")\n",
    "plt.close()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4.7 Rolling Alpha (36 mois)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "window = 36\n",
    "rolling_alpha = []\n",
    "dates = []\n",
    "\n",
    "for i in range(window, len(data)):\n",
    "    y_roll = data[\"GARP_Excess\"].iloc[i-window:i]\n",
    "    X_roll = sm.add_constant(data[[\"Mkt_RF\",\"SMB\",\"HML\",\"MOM\"]].iloc[i-window:i])\n",
    "    \n",
    "    model_roll = sm.OLS(y_roll, X_roll).fit(\n",
    "        cov_type=\"HAC\", cov_kwds={\"maxlags\":3}\n",
    "    )\n",
    "    rolling_alpha.append(model_roll.params[\"const\"] * 12)\n",
    "    dates.append(data.index[i])\n",
    "\n",
    "rolling_alpha = pd.Series(rolling_alpha, index=dates)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(rolling_alpha, label=\"Rolling Alpha (Carhart)\")\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.title(\"Alpha glissant (36 mois) – Carhart\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FIGURES / \"4_rolling_alpha_carhart.png\")\n",
    "plt.close()\n",
    "\n",
    "rolling_alpha.to_csv(RESULTS_TABLES / \"4_rolling_alpha_carhart.csv\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4.8 Test d'autocorrélation des résidus (Ljung-Box)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "ljung_box = acorr_ljungbox(model_carhart.resid, lags=[6], return_df=True)\n",
    "ljung_box.to_csv(RESULTS_TABLES / \"4_ljung_box_test.csv\")\n",
    "\n",
    "print(\"\\n======= CONTRIBUTION ANNUALISEE =======\\n\")\n",
    "print(contribution.round(4))\n",
    "\n",
    "print(\"\\n======= TEST LJUNG-BOX (résidus Carhart) =======\\n\")\n",
    "print(ljung_box)\n",
    "\n",
    "print(\"\\nSection 4 terminée avec succès.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f3968",
   "metadata": {},
   "source": [
    "# 5. Persistance du couple rendement–risque\n",
    "\n",
    "Cette section analyse la **stabilité et la persistance** des performances du portefeuille GARP dans le temps, à travers plusieurs indicateurs et tests statistiques :\n",
    "\n",
    "- **Rolling Sharpe ratio (12 mois)** : pour observer la variation du rendement ajusté du risque.\n",
    "- **Rolling Information Ratio vs MSCI World (12 mois)** : pour suivre la surperformance relative.\n",
    "- **Rolling Alpha (Carhart 4F, 36 mois)** : pour examiner la persistance du rendement excédentaire ajusté aux facteurs.\n",
    "- **Test AR(1) sur les rendements** : pour détecter l’auto-corrélation.\n",
    "- **Auto-corrélation du Sharpe ratio** : pour analyser la persistance du couple rendement/risque.\n",
    "- **Analyse par régimes de marché (bull / bear)** : pour comparer la performance selon le contexte.\n",
    "- **Test de stabilité structurelle (CUSUM)** : pour identifier d’éventuels changements dans la dynamique du portefeuille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "895b69fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TEST AR(1) RENDEMENTS =====\n",
      "Coefficient AR(1)   -0.129834\n",
      "p-value              0.145034\n",
      "R²                   0.016821\n",
      "dtype: float64\n",
      "\n",
      "===== PERSISTANCE SHARPE =====\n",
      "AR(1) Sharpe    8.959861e-01\n",
      "p-value         1.701285e-46\n",
      "dtype: float64\n",
      "\n",
      "===== ANALYSE REGIMES =====\n",
      "                       Bull Market  Bear Market\n",
      "Rendement annualisé       0.575972    -0.460055\n",
      "Volatilité annualisée     0.164396     0.142829\n",
      "Sharpe                    3.301155    -3.415247\n",
      "\n",
      "===== TEST CUSUM =====\n",
      "CUSUM Statistic    0.759625\n",
      "p-value            0.610990\n",
      "dtype: float64\n",
      "\n",
      "Section 5 terminée avec succès.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 5. PERSISTANCE DU COUPLE RENDEMENT–RISQUE\n",
    "# ======================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from statsmodels.stats.diagnostic import breaks_cusumolsresid\n",
    "\n",
    "RESULTS_TABLES = Path(\"../results/tables\")\n",
    "RESULTS_FIGURES = Path(\"../results/figures\")\n",
    "DATA_RAW = Path(\"../data/raw\")\n",
    "\n",
    "RESULTS_TABLES.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_FIGURES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 5.1 Intégration du RF Fama-French\n",
    "# ------------------------------------------------------\n",
    "\n",
    "ff = pd.read_excel(DATA_RAW / \"fama_french_3factors.xlsx\")\n",
    "\n",
    "ff.iloc[:, 0] = pd.to_datetime(ff.iloc[:, 0])\n",
    "ff.set_index(ff.columns[0], inplace=True)\n",
    "ff = ff.sort_index()\n",
    "\n",
    "ff.columns = [\"Mkt_RF\", \"SMB\", \"HML\", \"RF\"]\n",
    "\n",
    "# Conversion % -> décimal\n",
    "ff = ff / 100\n",
    "\n",
    "rf_series = ff[\"RF\"].reindex(garp_portfolio_returns.index)\n",
    "\n",
    "# Excess returns du portefeuille\n",
    "excess_returns = garp_portfolio_returns - rf_series\n",
    "\n",
    "window = 12\n",
    "\n",
    "# ======================================================\n",
    "# 5.2 Rolling Sharpe (12 mois)\n",
    "# ======================================================\n",
    "\n",
    "rolling_mean = excess_returns.rolling(window).mean() * 12\n",
    "rolling_vol = garp_portfolio_returns.rolling(window).std() * np.sqrt(12)\n",
    "\n",
    "rolling_sharpe = rolling_mean / rolling_vol\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(rolling_sharpe, label=\"Rolling Sharpe (12m)\")\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.title(\"Rolling Sharpe Ratio – GARP\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FIGURES / \"5_rolling_sharpe.png\")\n",
    "plt.close()\n",
    "\n",
    "rolling_sharpe.to_csv(RESULTS_TABLES / \"5_rolling_sharpe.csv\")\n",
    "\n",
    "# ======================================================\n",
    "# 5.3 Rolling Information Ratio vs MSCI World\n",
    "# ======================================================\n",
    "\n",
    "active_returns = returns_comp[\"GARP\"] - returns_comp[\"MSCI_World\"]\n",
    "\n",
    "rolling_active_mean = active_returns.rolling(window).mean() * 12\n",
    "rolling_tracking_error = active_returns.rolling(window).std() * np.sqrt(12)\n",
    "\n",
    "rolling_ir = rolling_active_mean / rolling_tracking_error\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(rolling_ir, label=\"Rolling Information Ratio\")\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.title(\"Rolling Information Ratio – GARP vs MSCI World\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FIGURES / \"5_rolling_information_ratio.png\")\n",
    "plt.close()\n",
    "\n",
    "rolling_ir.to_csv(RESULTS_TABLES / \"5_rolling_information_ratio.csv\")\n",
    "\n",
    "# ======================================================\n",
    "# 5.4 Rolling Alpha (Carhart 4F)\n",
    "# ======================================================\n",
    "\n",
    "window_reg = 36\n",
    "rolling_alpha = []\n",
    "dates = []\n",
    "\n",
    "for i in range(window_reg, len(data)):\n",
    "    \n",
    "    sub = data.iloc[i-window_reg:i]\n",
    "    y_sub = sub[\"GARP_Excess\"]\n",
    "    X_sub = sm.add_constant(sub[[\"Mkt_RF\",\"SMB\",\"HML\",\"MOM\"]])\n",
    "    \n",
    "    model_sub = sm.OLS(y_sub, X_sub).fit(\n",
    "        cov_type=\"HAC\", cov_kwds={\"maxlags\":3}\n",
    "    )\n",
    "    \n",
    "    rolling_alpha.append(model_sub.params[\"const\"] * 12)\n",
    "    dates.append(data.index[i])\n",
    "\n",
    "rolling_alpha = pd.Series(rolling_alpha, index=dates)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(rolling_alpha, label=\"Rolling Alpha (Carhart)\")\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.title(\"Rolling Alpha (36 mois)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FIGURES / \"5_rolling_alpha_carhart.png\")\n",
    "plt.close()\n",
    "\n",
    "rolling_alpha.to_csv(RESULTS_TABLES / \"5_rolling_alpha_carhart.csv\")\n",
    "\n",
    "# ======================================================\n",
    "# 5.5 Test de persistance AR(1) des rendements\n",
    "# ======================================================\n",
    "\n",
    "ar_model = sm.OLS(\n",
    "    garp_portfolio_returns[1:],\n",
    "    sm.add_constant(garp_portfolio_returns.shift(1)[1:])\n",
    ").fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":3})\n",
    "\n",
    "phi = ar_model.params.iloc[1]\n",
    "p_value_phi = ar_model.pvalues.iloc[1]\n",
    "\n",
    "ar_results = pd.Series({\n",
    "    \"Coefficient AR(1)\": phi,\n",
    "    \"p-value\": p_value_phi,\n",
    "    \"R²\": ar_model.rsquared\n",
    "})\n",
    "\n",
    "ar_results.to_csv(RESULTS_TABLES / \"5_ar1_persistence_test.csv\")\n",
    "\n",
    "# ======================================================\n",
    "# 5.6 Persistance du Sharpe\n",
    "# ======================================================\n",
    "\n",
    "sharpe_series = rolling_sharpe.dropna()\n",
    "\n",
    "ar_sharpe = sm.OLS(\n",
    "    sharpe_series[1:],\n",
    "    sm.add_constant(sharpe_series.shift(1)[1:])\n",
    ").fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":3})\n",
    "\n",
    "sharpe_persistence = pd.Series({\n",
    "    \"AR(1) Sharpe\": ar_sharpe.params.iloc[1],\n",
    "    \"p-value\": ar_sharpe.pvalues.iloc[1]\n",
    "})\n",
    "\n",
    "sharpe_persistence.to_csv(RESULTS_TABLES / \"5_sharpe_persistence_test.csv\")\n",
    "\n",
    "# ======================================================\n",
    "# 5.7 Analyse par régimes de marché\n",
    "# ======================================================\n",
    "\n",
    "aligned_data = pd.concat([\n",
    "    garp_portfolio_returns,\n",
    "    returns_comp[\"MSCI_World\"]\n",
    "], axis=1).dropna()\n",
    "\n",
    "aligned_data.columns = [\"GARP\", \"MSCI_World\"]\n",
    "\n",
    "bull = aligned_data[\"MSCI_World\"] > 0\n",
    "bear = aligned_data[\"MSCI_World\"] <= 0\n",
    "\n",
    "def regime_stats(mask):\n",
    "    \n",
    "    series = aligned_data[\"GARP\"][mask]\n",
    "    rf_regime = rf_series.reindex(series.index)\n",
    "    excess = series - rf_regime\n",
    "    \n",
    "    return pd.Series({\n",
    "        \"Rendement annualisé\": series.mean() * 12,\n",
    "        \"Volatilité annualisée\": series.std() * np.sqrt(12),\n",
    "        \"Sharpe\": (excess.mean() * 12) / (series.std() * np.sqrt(12))\n",
    "    })\n",
    "\n",
    "regime_analysis = pd.DataFrame({\n",
    "    \"Bull Market\": regime_stats(bull),\n",
    "    \"Bear Market\": regime_stats(bear)\n",
    "})\n",
    "\n",
    "regime_analysis.to_csv(RESULTS_TABLES / \"5_regime_analysis.csv\")\n",
    "\n",
    "# ======================================================\n",
    "# 5.8 Test de stabilité structurelle (CUSUM)\n",
    "# ======================================================\n",
    "\n",
    "cusum_test = breaks_cusumolsresid(ar_model.resid, ddof=1)\n",
    "\n",
    "cusum_results = pd.Series({\n",
    "    \"CUSUM Statistic\": cusum_test[0],\n",
    "    \"p-value\": cusum_test[1]\n",
    "})\n",
    "\n",
    "cusum_results.to_csv(RESULTS_TABLES / \"5_cusum_stability_test.csv\")\n",
    "\n",
    "# ======================================================\n",
    "# 5.9 Affichage synthétique\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\n===== TEST AR(1) RENDEMENTS =====\")\n",
    "print(ar_results)\n",
    "\n",
    "print(\"\\n===== PERSISTANCE SHARPE =====\")\n",
    "print(sharpe_persistence)\n",
    "\n",
    "print(\"\\n===== ANALYSE REGIMES =====\")\n",
    "print(regime_analysis)\n",
    "\n",
    "print(\"\\n===== TEST CUSUM =====\")\n",
    "print(cusum_results)\n",
    "\n",
    "print(\"\\nSection 5 terminée avec succès.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d46991",
   "metadata": {},
   "source": [
    "# 6. Analyse de robustesse\n",
    "\n",
    "Cette section évalue la **robustesse des résultats** du portefeuille GARP face à différents choix méthodologiques, périodes et coûts. Les tests effectués incluent :\n",
    "\n",
    "- **Benchmark alternatif** : comparaison avec le FTSE All-World.\n",
    "- **Bootstrap de l’alpha** : estimation de la distribution de l’alpha pour vérifier sa significativité.\n",
    "- **Sous-périodes** : analyse des performances sur différentes périodes.\n",
    "- **Impact des coûts de transaction** : ajustement des rendements pour des frais hypothétiques.\n",
    "- **Spécification des rendements** : log returns vs simple returns.\n",
    "- **Exclusion d’une période extrême** :  tester la sensibilité aux événements exceptionnels (exemple : 2022).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b048289a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7982/164581566.py:33: Pandas4Warning: Sorting by default when concatenating all DatetimeIndex is deprecated.  In the future, pandas will respect the default of `sort=False`. Specify `sort=True` or `sort=False` to silence this message. If you see this warnings when not directly calling concat, report a bug to pandas.\n",
      "  returns_robust = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ROBUSTESSE BENCHMARK =====\n",
      "Tracking Error       0.142793\n",
      "Information Ratio    0.674788\n",
      "dtype: float64\n",
      "\n",
      "===== BOOTSTRAP ALPHA =====\n",
      "Alpha moyen (bootstrap)    0.075248\n",
      "IC 2.5%                   -0.059327\n",
      "IC 97.5%                   0.211208\n",
      "dtype: float64\n",
      "\n",
      "===== IMPACT COUTS DE TRANSACTION =====\n",
      "Rendement annualisé net    0.203979\n",
      "Sharpe net                 0.840604\n",
      "dtype: float64\n",
      "\n",
      "Section 6 terminée avec succès.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 6. ANALYSE DE ROBUSTESSE\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "RESULTS_FIGURES = Path(\"../results/figures\")\n",
    "RESULTS_TABLES = Path(\"../results/tables\")\n",
    "\n",
    "RESULTS_FIGURES.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_TABLES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_RAW = Path(\"../data/raw\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6.1 ROBUSTESSE AU BENCHMARK – FTSE ALL-WORLD\n",
    "# ------------------------------------------------------\n",
    "\n",
    "ftse_aw = pd.read_excel(DATA_RAW / \"ftse_all_world_factset.xlsx\")\n",
    "\n",
    "ftse_aw.iloc[:,0] = pd.to_datetime(ftse_aw.iloc[:,0])\n",
    "ftse_aw.set_index(ftse_aw.columns[0], inplace=True)\n",
    "ftse_aw = ftse_aw.sort_index().iloc[:,0]\n",
    "ftse_aw.name = \"FTSE_All_World\"\n",
    "\n",
    "# Simple returns\n",
    "r_ftse = ftse_aw.pct_change()\n",
    "\n",
    "returns_robust = pd.concat(\n",
    "    [garp_portfolio_returns, r_ftse], axis=1\n",
    ").dropna()\n",
    "\n",
    "returns_robust.columns = [\"GARP\",\"FTSE\"]\n",
    "\n",
    "# Performance cumulée (simple returns)\n",
    "cumulative = (1 + returns_robust).cumprod()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cumulative[\"GARP\"], label=\"GARP\")\n",
    "plt.plot(cumulative[\"FTSE\"], linestyle=\"--\", label=\"FTSE All-World\")\n",
    "plt.title(\"Robustesse – Benchmark alternatif\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FIGURES / \"6_benchmark_robustesse.png\")\n",
    "plt.close()\n",
    "\n",
    "# Information Ratio vs FTSE\n",
    "active = returns_robust[\"GARP\"] - returns_robust[\"FTSE\"]\n",
    "tracking_error = active.std() * np.sqrt(12)\n",
    "information_ratio = (active.mean() * 12) / tracking_error\n",
    "\n",
    "benchmark_stats = pd.Series({\n",
    "    \"Tracking Error\": tracking_error,\n",
    "    \"Information Ratio\": information_ratio\n",
    "})\n",
    "\n",
    "benchmark_stats.to_csv(RESULTS_TABLES / \"6_ftse_information_ratio.csv\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6.2 INTÉGRATION DU RF FAMA-FRENCH\n",
    "# ------------------------------------------------------\n",
    "\n",
    "ff = pd.read_excel(DATA_RAW / \"fama_french_3factors.xlsx\")\n",
    "\n",
    "ff.iloc[:,0] = pd.to_datetime(ff.iloc[:,0])\n",
    "ff.set_index(ff.columns[0], inplace=True)\n",
    "ff = ff.sort_index()\n",
    "\n",
    "ff.columns = [\"Mkt_RF\",\"SMB\",\"HML\",\"RF\"]\n",
    "\n",
    "# Conversion % -> décimal\n",
    "ff = ff / 100\n",
    "\n",
    "rf_series = ff[\"RF\"].reindex(returns_robust.index)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6.3 ROBUSTESSE STATISTIQUE – BOOTSTRAP ALPHA\n",
    "# ------------------------------------------------------\n",
    "\n",
    "excess = returns_robust[\"GARP\"] - rf_series\n",
    "market_excess = returns_robust[\"FTSE\"] - rf_series\n",
    "\n",
    "n_boot = 5000\n",
    "alpha_boot = []\n",
    "\n",
    "for _ in range(n_boot):\n",
    "    \n",
    "    sample_idx = np.random.choice(len(excess), len(excess), replace=True)\n",
    "    \n",
    "    y = excess.iloc[sample_idx]\n",
    "    X = sm.add_constant(market_excess.iloc[sample_idx])\n",
    "    \n",
    "    model = sm.OLS(y, X).fit()\n",
    "    alpha_boot.append(model.params[\"const\"] * 12)\n",
    "\n",
    "alpha_boot = np.array(alpha_boot)\n",
    "\n",
    "ci_lower = np.percentile(alpha_boot, 2.5)\n",
    "ci_upper = np.percentile(alpha_boot, 97.5)\n",
    "\n",
    "bootstrap_results = pd.Series({\n",
    "    \"Alpha moyen (bootstrap)\": alpha_boot.mean(),\n",
    "    \"IC 2.5%\": ci_lower,\n",
    "    \"IC 97.5%\": ci_upper\n",
    "})\n",
    "\n",
    "bootstrap_results.to_csv(RESULTS_TABLES / \"6_bootstrap_alpha.csv\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(alpha_boot, bins=40)\n",
    "plt.axvline(ci_lower, color=\"red\", linestyle=\"--\")\n",
    "plt.axvline(ci_upper, color=\"red\", linestyle=\"--\")\n",
    "plt.title(\"Distribution Bootstrap de l'Alpha (annualisé)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FIGURES / \"6_bootstrap_alpha_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6.4 ROBUSTESSE AUX SOUS-PÉRIODES\n",
    "# ------------------------------------------------------\n",
    "\n",
    "mid = len(returns_robust)//2\n",
    "sub1 = returns_robust.iloc[:mid]\n",
    "sub2 = returns_robust.iloc[mid:]\n",
    "\n",
    "def perf(df):\n",
    "    \n",
    "    rf_sub = rf_series.reindex(df.index)\n",
    "    excess_sub = df[\"GARP\"] - rf_sub\n",
    "    \n",
    "    return pd.Series({\n",
    "        \"Rendement annualisé\": df[\"GARP\"].mean()*12,\n",
    "        \"Volatilité annualisée\": df[\"GARP\"].std()*np.sqrt(12),\n",
    "        \"Sharpe\": (excess_sub.mean()*12)/(df[\"GARP\"].std()*np.sqrt(12))\n",
    "    })\n",
    "\n",
    "subperiod_results = pd.DataFrame({\n",
    "    \"Sous-période 1\": perf(sub1),\n",
    "    \"Sous-période 2\": perf(sub2)\n",
    "})\n",
    "\n",
    "subperiod_results.to_csv(RESULTS_TABLES / \"6_subperiod_robustesse.csv\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6.5 ROBUSTESSE AUX COÛTS DE TRANSACTION\n",
    "# ------------------------------------------------------\n",
    "\n",
    "transaction_cost = 0.002  # 20 bps par mois hypothétique\n",
    "\n",
    "returns_net = garp_portfolio_returns - transaction_cost/12\n",
    "\n",
    "rf_net = ff[\"RF\"].reindex(returns_net.index)\n",
    "excess_net = returns_net - rf_net\n",
    "\n",
    "net_stats = pd.Series({\n",
    "    \"Rendement annualisé net\": returns_net.mean()*12,\n",
    "    \"Sharpe net\": (excess_net.mean()*12)/(returns_net.std()*np.sqrt(12))\n",
    "})\n",
    "\n",
    "net_stats.to_csv(RESULTS_TABLES / \"6_transaction_cost_impact.csv\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6.6 COMPARAISON ARITHMÉTIQUE VS GÉOMÉTRIQUE\n",
    "# ------------------------------------------------------\n",
    "\n",
    "geo_return = (1 + garp_portfolio_returns).prod()**(12/len(garp_portfolio_returns)) - 1\n",
    "arith_return = garp_portfolio_returns.mean()*12\n",
    "\n",
    "spec_comparison = pd.Series({\n",
    "    \"Rendement annualisé (arithmétique)\": arith_return,\n",
    "    \"Rendement annualisé (géométrique)\": geo_return\n",
    "})\n",
    "\n",
    "spec_comparison.to_csv(RESULTS_TABLES / \"6_specification_comparison.csv\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6.7 EXCLUSION D'UNE PÉRIODE EXTRÊME\n",
    "# ------------------------------------------------------\n",
    "\n",
    "filtered = garp_portfolio_returns[garp_portfolio_returns.index.year != 2022]\n",
    "\n",
    "extreme_test = pd.Series({\n",
    "    \"Rendement annualisé (complet)\": garp_portfolio_returns.mean()*12,\n",
    "    \"Rendement annualisé (sans 2022)\": filtered.mean()*12\n",
    "})\n",
    "\n",
    "extreme_test.to_csv(RESULTS_TABLES / \"6_extreme_period_test.csv\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 6.8 AFFICHAGE SYNTHÉTIQUE\n",
    "# ------------------------------------------------------\n",
    "\n",
    "print(\"\\n===== ROBUSTESSE BENCHMARK =====\")\n",
    "print(benchmark_stats)\n",
    "\n",
    "print(\"\\n===== BOOTSTRAP ALPHA =====\")\n",
    "print(bootstrap_results)\n",
    "\n",
    "print(\"\\n===== IMPACT COUTS DE TRANSACTION =====\")\n",
    "print(net_stats)\n",
    "\n",
    "print(\"\\nSection 6 terminée avec succès.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
